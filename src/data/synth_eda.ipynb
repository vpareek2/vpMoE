{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85bbdd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a685e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dir = Path(os.environ.get(\"SYNTH_DIR\", \"/datasets/PleIAs_synth\"))\n",
    "shards = sorted(synth_dir.glob(\"synth_*.parquet\"))\n",
    "assert shards, f\"No shards found in {synth_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16db10ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first shard: synth_001.parquet\n",
      "rows: 154674\n",
      "schema: <pyarrow._parquet.ParquetSchema object at 0xe92d80275b00>\n",
      "required group field_id=-1 schema {\n",
      "  optional binary field_id=-1 synth_id (String);\n",
      "  optional binary field_id=-1 language (String);\n",
      "  optional binary field_id=-1 exercise (String);\n",
      "  optional binary field_id=-1 model (String);\n",
      "  optional binary field_id=-1 query (String);\n",
      "  optional binary field_id=-1 query_seed_url (String);\n",
      "  optional binary field_id=-1 query_seed_text (String);\n",
      "  optional binary field_id=-1 additional_seed_url (String);\n",
      "  optional binary field_id=-1 seed_license (String);\n",
      "  optional binary field_id=-1 constraints (String);\n",
      "  optional binary field_id=-1 script (String);\n",
      "  optional binary field_id=-1 synthetic_reasoning (String);\n",
      "  optional binary field_id=-1 synthetic_answer (String);\n",
      "  optional int64 field_id=-1 words;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first = shards[0]\n",
    "pf = pq.ParquetFile(first)\n",
    "print(\"first shard:\", first.name)\n",
    "print(\"rows:\", pf.metadata.num_rows)\n",
    "print(\"schema:\", pf.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e02f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synth_id</th>\n",
       "      <th>language</th>\n",
       "      <th>exercise</th>\n",
       "      <th>model</th>\n",
       "      <th>query</th>\n",
       "      <th>query_seed_text</th>\n",
       "      <th>constraints</th>\n",
       "      <th>synthetic_reasoning</th>\n",
       "      <th>synthetic_answer</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memorization_german_10_150696</td>\n",
       "      <td>de</td>\n",
       "      <td>memorization</td>\n",
       "      <td>qwen-3-8b-memorization</td>\n",
       "      <td>Wie genau interagieren die Wärmegradienten zwi...</td>\n",
       "      <td>Climate\\n\\nThe sea climate has warm waters and...</td>\n",
       "      <td></td>\n",
       "      <td>**Query parsing**: \"Wie genau interagieren...\"...</td>\n",
       "      <td>Die Wärmegradienten zwischen dem kalten nordwe...</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>memorization_94_6343</td>\n",
       "      <td>en</td>\n",
       "      <td>memorization</td>\n",
       "      <td>qwen-3-8b-memorization</td>\n",
       "      <td>hey um can someone tell me why the decagon has...</td>\n",
       "      <td>Symmetry\\n\\nThe regular decagon has Dih symmet...</td>\n",
       "      <td></td>\n",
       "      <td>Query: \"why the decagon has like so many diffe...</td>\n",
       "      <td>You're right to notice that the decagon has mu...</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorization_82_52457</td>\n",
       "      <td>en</td>\n",
       "      <td>memorization</td>\n",
       "      <td>qwen-3-8b-memorization</td>\n",
       "      <td>Which animal has more poison - the salamander ...</td>\n",
       "      <td>Amphibians\\n\\nSome salamanders can extrude sha...</td>\n",
       "      <td></td>\n",
       "      <td>### 1. Query Parsing\\n\\n\"Which animal has more...</td>\n",
       "      <td>Both animals you're describing have developed ...</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        synth_id language      exercise  \\\n",
       "0  memorization_german_10_150696       de  memorization   \n",
       "1           memorization_94_6343       en  memorization   \n",
       "2          memorization_82_52457       en  memorization   \n",
       "\n",
       "                    model                                              query  \\\n",
       "0  qwen-3-8b-memorization  Wie genau interagieren die Wärmegradienten zwi...   \n",
       "1  qwen-3-8b-memorization  hey um can someone tell me why the decagon has...   \n",
       "2  qwen-3-8b-memorization  Which animal has more poison - the salamander ...   \n",
       "\n",
       "                                     query_seed_text constraints  \\\n",
       "0  Climate\\n\\nThe sea climate has warm waters and...               \n",
       "1  Symmetry\\n\\nThe regular decagon has Dih symmet...               \n",
       "2  Amphibians\\n\\nSome salamanders can extrude sha...               \n",
       "\n",
       "                                 synthetic_reasoning  \\\n",
       "0  **Query parsing**: \"Wie genau interagieren...\"...   \n",
       "1  Query: \"why the decagon has like so many diffe...   \n",
       "2  ### 1. Query Parsing\\n\\n\"Which animal has more...   \n",
       "\n",
       "                                    synthetic_answer  words  \n",
       "0  Die Wärmegradienten zwischen dem kalten nordwe...    564  \n",
       "1  You're right to notice that the decagon has mu...    577  \n",
       "2  Both animals you're describing have developed ...    443  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"synth_id\",\"language\",\"exercise\",\"model\",\n",
    "    \"query\",\"query_seed_text\",\"constraints\",\n",
    "    \"synthetic_reasoning\",\"synthetic_answer\",\"words\",\n",
    "]\n",
    "\n",
    "preview = pq.read_table(first, columns=cols).slice(0, 3).to_pandas()\n",
    "preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd700c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample rows: 20000 from shards: 5\n"
     ]
    }
   ],
   "source": [
    "n_shards = 5\n",
    "sample_per_shard = 4000\n",
    "\n",
    "dfs = []\n",
    "for p in shards[:n_shards]:\n",
    "    t = pq.read_table(p, columns=cols).slice(0, sample_per_shard)\n",
    "    d = t.to_pandas()\n",
    "    d[\"shard\"] = p.name\n",
    "    dfs.append(d)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"sample rows:\", len(df), \"from shards:\", n_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8706f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_seed_text      missing_frac=0.000\n",
      "constraints          missing_frac=0.000\n",
      "synthetic_reasoning  missing_frac=0.000\n",
      "synthetic_answer     missing_frac=0.000\n"
     ]
    }
   ],
   "source": [
    "def miss_frac(s: pd.Series) -> float:\n",
    "    if s.dtype == \"object\":\n",
    "        return float(s.isna().mean())\n",
    "    return float(s.isna().mean())\n",
    "\n",
    "for c in [\"query_seed_text\",\"constraints\",\"synthetic_reasoning\",\"synthetic_answer\"]:\n",
    "    print(f\"{c:20s} missing_frac={miss_frac(df[c]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1bd263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top exercise:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "exercise\n",
       "memorization           18152\n",
       "mcq                      414\n",
       "math exercise            333\n",
       "constrained writing      316\n",
       "rag                      206\n",
       "math mcq                 177\n",
       "editing                  159\n",
       "creative writing         148\n",
       "cooking                   95\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top language:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    16177\n",
       "es      649\n",
       "fr      642\n",
       "de      641\n",
       "it      628\n",
       "pl      620\n",
       "nl      306\n",
       "la      303\n",
       "pt        5\n",
       "uk        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model\n",
       "qwen-3-8b-memorization                              18152\n",
       "qwen-3-8b-mcq                                         414\n",
       "deepseek-prover-drafter+deepseek-prover-solving       333\n",
       "qwen-3-8b-constrained-writing                         316\n",
       "qwen-3-8b-rag                                         206\n",
       "qwen-3-8b-mcq-math+deepseek-prover-8b-solving         177\n",
       "qwen-3-8b-editing                                     159\n",
       "qwen-3-8b-creative-writing                            148\n",
       "qwen-3-8b-memorization+seed rewriting with Qwen3       95\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nTop exercise:\")\n",
    "display(df[\"exercise\"].value_counts().head(15))\n",
    "\n",
    "print(\"\\nTop language:\")\n",
    "display(df[\"language\"].value_counts().head(15))\n",
    "\n",
    "print(\"\\nTop model:\")\n",
    "display(df[\"model\"].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8771a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query                p50=159 p90=433 p95=560 p99=1015 max=8279\n",
      "query_seed_text      p50=702 p90=2470 p95=3358 p99=5579 max=14211\n",
      "synthetic_reasoning  p50=2252 p90=3256 p95=3583 p99=4425 max=10058\n",
      "synthetic_answer     p50=1417 p90=1902 p95=2091 p99=4496 max=15320\n"
     ]
    }
   ],
   "source": [
    "def len_stats(series: pd.Series, name: str):\n",
    "    s = series.fillna(\"\").astype(str)\n",
    "    q = s.str.len().quantile([0.5, 0.9, 0.95, 0.99]).to_dict()\n",
    "    mx = int(s.str.len().max())\n",
    "    print(f\"{name:20s} p50={int(q[0.5])} p90={int(q[0.9])} p95={int(q[0.95])} p99={int(q[0.99])} max={mx}\")\n",
    "\n",
    "for c in [\"query\",\"query_seed_text\",\"synthetic_reasoning\",\"synthetic_answer\"]:\n",
    "    len_stats(df[c], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9163dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c727a1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_toks</th>\n",
       "      <th>reasoning_toks</th>\n",
       "      <th>answer_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>275.882000</td>\n",
       "      <td>426.319000</td>\n",
       "      <td>270.956500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>254.310702</td>\n",
       "      <td>221.744223</td>\n",
       "      <td>163.589353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>191.000000</td>\n",
       "      <td>466.500000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>600.100000</td>\n",
       "      <td>669.000000</td>\n",
       "      <td>354.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>783.350000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>414.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1270.160000</td>\n",
       "      <td>929.020000</td>\n",
       "      <td>994.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2112.000000</td>\n",
       "      <td>1327.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_toks  reasoning_toks  answer_toks\n",
       "count  2000.000000     2000.000000  2000.000000\n",
       "mean    275.882000      426.319000   270.956500\n",
       "std     254.310702      221.744223   163.589353\n",
       "min       9.000000        0.000000     4.000000\n",
       "50%     191.000000      466.500000   255.000000\n",
       "90%     600.100000      669.000000   354.100000\n",
       "95%     783.350000      731.000000   414.100000\n",
       "99%    1270.160000      929.020000   994.030000\n",
       "max    2112.000000     1327.000000  2880.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_toks</th>\n",
       "      <th>reasoning_toks</th>\n",
       "      <th>answer_toks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creative writing</th>\n",
       "      <td>514.0</td>\n",
       "      <td>1245.5</td>\n",
       "      <td>1839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constrained writing</th>\n",
       "      <td>603.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1207.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>editing</th>\n",
       "      <td>1353.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag</th>\n",
       "      <td>713.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memorization</th>\n",
       "      <td>585.4</td>\n",
       "      <td>663.0</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math exercise</th>\n",
       "      <td>868.2</td>\n",
       "      <td>620.0</td>\n",
       "      <td>328.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooking</th>\n",
       "      <td>612.2</td>\n",
       "      <td>775.8</td>\n",
       "      <td>271.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcq</th>\n",
       "      <td>646.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math mcq</th>\n",
       "      <td>747.1</td>\n",
       "      <td>1053.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prompt_toks  reasoning_toks  answer_toks\n",
       "exercise                                                     \n",
       "creative writing           514.0          1245.5       1839.0\n",
       "constrained writing        603.0             0.0       1207.6\n",
       "editing                   1353.6             0.0        685.0\n",
       "rag                        713.0           728.0        592.0\n",
       "memorization               585.4           663.0        341.0\n",
       "math exercise              868.2           620.0        328.6\n",
       "cooking                    612.2           775.8        271.2\n",
       "mcq                        646.0           632.0         29.0\n",
       "math mcq                   747.1          1053.9          6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = df.sample(n=min(2000, len(df)), random_state=0).copy()\n",
    "\n",
    "def toklen(x: str) -> int:\n",
    "    return len(enc.encode(x or \"\"))\n",
    "\n",
    "sample[\"prompt_toks\"] = (\n",
    "    sample[\"query\"].astype(str).map(toklen)\n",
    "    + sample[\"query_seed_text\"].fillna(\"\").astype(str).map(toklen)\n",
    ")\n",
    "sample[\"reasoning_toks\"] = sample[\"synthetic_reasoning\"].fillna(\"\").astype(str).map(toklen)\n",
    "sample[\"answer_toks\"] = sample[\"synthetic_answer\"].fillna(\"\").astype(str).map(toklen)\n",
    "\n",
    "display(sample[[\"prompt_toks\",\"reasoning_toks\",\"answer_toks\"]].describe(percentiles=[.5,.9,.95,.99]))\n",
    "display(\n",
    "    sample.groupby(\"exercise\")[[\"prompt_toks\",\"reasoning_toks\",\"answer_toks\"]]\n",
    "    .quantile(0.9)\n",
    "    .sort_values(\"answer_toks\", ascending=False)\n",
    "    .head(20)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d174ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "exercise: memorization | id: memorization_specialized_18_1_4222 | lang: en | model: qwen-3-8b-memorization\n",
      "\n",
      "QUERY:\n",
      " What will happen to the planet if we don't reduce meat consumption to less than a billion meat-eaters?\n",
      "\n",
      "SEED (trunc):\n",
      " We must change our diet. The planet can't support billions of meat-eaters.\n",
      "\n",
      "REASONING (trunc):\n",
      " Query: \"What will happen to the planet if we don't reduce meat consumption to less than a billion meat-eaters?\"\n",
      "\n",
      "Parse components:\n",
      "- \"don't reduce\" → assume current consumption patterns continue\n",
      "- \"less than a billion meat-eaters\" → threshold claim needing verification\n",
      "- \"what will happen\" → predictive analysis\n",
      "\n",
      "### 1. Threshold Validation\n",
      "\n",
      "\"Less than a billion meat-eaters\" - questionable premise.\n",
      "\n",
      "Global population ≈7.9B (2024). Current meat-eaters ≈3.3B (est). \n",
      "→ Billion meat-eaters = 27% of population? Or billion total people?\n",
      "\n",
      "Semantic ambiguity. Response suggests billion total people, not meat-eaters specifically.\n",
      "\n",
      "Need to verify: What threshold actually matters?\n",
      "\n",
      "### 2. Resource Modeling\n",
      "\n",
      "Meat production constraints:\n",
      "- Land: Cattle require 8x more land than plant-based calories\n",
      "- Water: 15x more water for beef than wheat\n",
      "- Emissions: Livestock = 14.5% global emissions\n",
      "\n",
      "Current traj\n",
      "\n",
      "ANSWER (trunc):\n",
      " The premise of reducing meat consumption to \"less than a billion meat-eaters\" seems to be based on the idea that current population levels are unsustainable for meat-heavy diets. However, this specific threshold is difficult to assess definitively.\n",
      "\n",
      "The concern around meat consumption relates to its significant environmental impact - livestock agriculture requires substantial resources, contributes to greenhouse gas emissions, and competes for land and water. Current meat production systems are indeed resource-intensive and environmentally taxing.\n",
      "\n",
      "A more nuanced perspective suggests that moderate meat consumption levels may actually be compatible with climate targets and broader sustainable development goals, even for very large populations of around 10 billion people. This implies that the issue may not necessarily be about reducing the number of meat-eaters, but rather about how much \n",
      "\n",
      "====================================================================================================\n",
      "exercise: mcq | id: synth_memory_mcq_2_113695 | lang: en | model: qwen-3-8b-mcq\n",
      "\n",
      "QUERY:\n",
      " The first widespread appearance of four-wheel drive tractors in agricultural machinery occurred during\n",
      "\n",
      "A. the 1930s\n",
      "B. the 1950s\n",
      "C. the 1960s\n",
      "D. the 1980s\n",
      "\n",
      "SEED (trunc):\n",
      " Configuration\n",
      "\n",
      "Tractors can be generally classified by number of axles or wheels, with main categories of two-wheel tractors (single-axle tractors) and four-wheel tractors (two-axle tractors); more axles are possible but uncommon. Among four-wheel tractors (two-axle tractors), most are two-wheel drive (usually at the rear); but many are two-wheel drive with front wheel assist, four-wheel drive (often with articulated steering), or track crawler (with steel or rubber tracks).\n",
      "\n",
      "The classic farm tractor is a simple open vehicle, with two very large driving wheels on an axle below a single seat (the seat and steering wheel consequently are in the center), and the engine in front of the driver, with two steerable wheels below the engine compartment. This basic design has remained unchanged for a number of years after being pioneered by Wallis, but enclosed cabs are fitted on almost all modern\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " domain:history, exercise:fact recall, answer_shape:standard, exercise_pattern:sentence_following\n",
      "\n",
      "REASONING (trunc):\n",
      " ### 1. Query Analysis\n",
      "\n",
      "\"First widespread appearance of four-wheel drive tractors in agricultural machinery occurred during\"\n",
      "\n",
      "Key terms: \"first widespread\", \"four-wheel drive\", \"agricultural machinery\", \"occurred during\"\n",
      "\n",
      "→ Temporal question requiring historical knowledge of tractor development\n",
      "→ \"Widespread\" suggests adoption beyond early prototypes/limited use\n",
      "→ Agricultural context narrows to farm equipment domain\n",
      "\n",
      "### 2. Historical Context Mapping\n",
      "\n",
      "Tractor evolution timeline:\n",
      "- Early 1900s: Two-wheel designs dominant ●\n",
      "- Mid-century: Agricultural mechanization accelerating ◐\n",
      "- 1930s-1940s: Great Depression/WWII → resource constraints ⚠\n",
      "- Post-war period: Agricultural intensification ◐\n",
      "- 1950s-1960s: Mechanization expansion ●\n",
      "- 1980s: Computerization era ◐\n",
      "\n",
      "### 3. Four-Wheel Drive Development Logic\n",
      "\n",
      "Two-wheel drive limitations:\n",
      "- Poor traction in wet/heavy soils\n",
      "- Reduced stability in \n",
      "\n",
      "ANSWER (trunc):\n",
      " C. the 1960s\n",
      "\n",
      "====================================================================================================\n",
      "exercise: math exercise | id: synth_math_21_14314 | lang: en | model: deepseek-prover-drafter+deepseek-prover-solving\n",
      "\n",
      "QUERY:\n",
      " A company that manufactures loudspeakers has three factories. Each factory assembles five drivers for a new \"coaxial Duplex\" system. In the final assembly step, each factory's production is combined with another driver to create one final system. How many final systems are produced in total?\n",
      "\n",
      "SEED (trunc):\n",
      " Loudspeaker\n",
      "\n",
      "First loudspeaker systems\n",
      "\n",
      "In the 1930s, loudspeaker manufacturers began to combine two and three drivers or sets of drivers each optimized for a different frequency range in order to improve frequency response and increase sound pressure level. In 1937, the first film industry-standard loudspeaker system, \"The Shearer Horn System for Theatres\", a two-way system, was introduced by Metro-Goldwyn-Mayer. It used four 15\" low-frequency drivers, a crossover network set for 375 Hz, and a single multi-cellular horn with two compression drivers providing the high frequencies. John Kenneth Hilliard, James Bullough Lansing, and Douglas Shearer all played roles in creating the system. At the 1939 New York World's Fair, a very large two-way public address system was mounted on a tower at Flushing Meadows. The eight 27\" low-frequency drivers were designed by Rudy Bozak in his role as chi\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " result:15\n",
      "\n",
      "REASONING (trunc):\n",
      " ### 1. Problem parsing, setup\n",
      "\n",
      "Reading carefully... \"Each factory assembles five drivers for a new 'coaxial Duplex' system.\" \n",
      "\n",
      "Wait. This phrasing suggests factory-level assembly vs system-level assembly. Two interpretations possible:\n",
      "- **Factory-centric**: Each factory produces 5 drivers, then combines them\n",
      "- **System-centric**: Each factory produces complete systems\n",
      "\n",
      "The phrase \"combined with another driver to create one final system\" suggests factory-level assembly → factory produces partial units.\n",
      "\n",
      "※ Key insight: \"combined with another driver\" implies factory-level intermediate step, not system-level.\n",
      "\n",
      "∴ Each factory: 5 drivers → combined → 1 final system\n",
      "\n",
      "### 2. Production flow analysis\n",
      "\n",
      "Factory 1: 5 drivers → 1 system\n",
      "Factory 2: 5 drivers → 1 system  \n",
      "Factory 3: 5 drivers → 1 system\n",
      "\n",
      "But wait - the problem states \"combined with another driver to create one final system.\" \n",
      "\n",
      "?maybe? \n",
      "\n",
      "ANSWER (trunc):\n",
      " **Answer: 15 systems**\n",
      "\n",
      "This is a **multi-step production problem** that requires careful interpretation of assembly processes and basic arithmetic operations.\n",
      "\n",
      "## Problem Analysis\n",
      "\n",
      "The key challenge lies in parsing the assembly process described:\n",
      "- Each factory assembles 5 drivers\n",
      "- \"Combined with another driver to create one final system\" - this phrasing suggests factory-level assembly rather than system-level assembly\n",
      "\n",
      "## Solution Approach\n",
      "\n",
      "The most logical interpretation is that each factory's production goes through an intermediate assembly stage:\n",
      "\n",
      "1. **Factory-level assembly**: Each factory produces 5 drivers\n",
      "2. **Intermediate step**: 5 drivers from one factory get combined with 5 drivers from another factory (10 drivers total per system)\n",
      "3. **Final assembly**: Each factory's combined 10 drivers produce 1 final system\n",
      "\n",
      "Therefore:\n",
      "- **Total drivers produced**: 3 factories × 10 drive\n",
      "\n",
      "====================================================================================================\n",
      "exercise: constrained writing | id: synth_dataset_writing_3_75374 | lang: en | model: qwen-3-8b-constrained-writing\n",
      "\n",
      "QUERY:\n",
      " Explain who Lee Iacocca was and what he accomplished. Please first repeat my request, then provide your explanation.\n",
      "\n",
      "SEED (trunc):\n",
      " Lido Anthony \"Lee\" Iacocca was an American automobile executive best known for the development of the Ford Mustang, Continental Mark III, and Ford Pinto cars while at the Ford Motor Company in the 1960s, and for reviving the Chrysler Corporation as its CEO during the 1980s. He was president of Chrysler from 1978 to 1991 and chairman and CEO from 1979 until his retirement at the end of 1992. He was one of the few executives to preside over the operations of two of the United States' Big Three automakers. Iacocca authored or co-authored several books, including Iacocca: An Autobiography, and Where Have All the Leaders Gone?.\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " combination:repeat_prompt\n",
      "\n",
      "REASONING (trunc):\n",
      " \n",
      "\n",
      "ANSWER (trunc):\n",
      " Explain who Lee Iacocca was and what he accomplished.\n",
      "\n",
      "Lee Iacocca was an American automotive executive celebrated for his visionary leadership and dramatic corporate turnarounds. Born Lydie Marie Iacocca, he became one of the most prominent figures in the history of the American automobile industry. His career was defined by two major tenures at iconic companies and his role in creating some of the 20th century's most influential vehicles.\n",
      "\n",
      "Iacocca’s first major impact was at the Ford Motor Company. He joined Ford in 1956 and rose through the ranks, becoming its president in 1960. During his time there, he championed the development of the Ford Mustang. Launched in 1964, the Mustang was an immediate and runaway success, capturing the imagination of a generation and fundamentally reshaping the automotive market. It was the best-selling car in the United States for four consecutive years,\n",
      "\n",
      "====================================================================================================\n",
      "exercise: rag | id: rag_2_152344 | lang: en | model: qwen-3-8b-rag\n",
      "\n",
      "QUERY:\n",
      " I wonder how aardvarks compare to other burrowing mammals in terms of digging efficiency.\n",
      "\n",
      "SEED (trunc):\n",
      " Aardvarks (/ ˈ ɑːr d v ɑːr k / ARD -vark; Orycteropus afer) are medium-sized, burrowing, nocturnal mammals native to Africa. They have a long snout, similar to that of a pig, which is used to sniff out food.\n",
      "\n",
      "Aardvarks are the only living species of the order Tubulidentata, although other prehistoric species and genera of Tubulidentata are known. They are afrotheres, a clade that also includes elephants, manatees, and hyraxes.\n",
      "\n",
      "They are found over much of the southern two-thirds of the African continent, avoiding areas that are mainly rocky. Nocturnal feeders, aardvarks subsist on ants and termites by using their sharp claws and powerful legs to dig the insects out of their hills. Aardvarks also dig to create burrows in which to live and rear their young.\n",
      "\n",
      "Aardvarks are listed as \"least concern\" by the IUCN, although their numbers are decreasing.\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " <source_1>\n",
      "Aardvarks (/ ˈ ɑːr d v ɑːr k / ARD -vark; Orycteropus afer) are medium-sized, burrowing, nocturnal mammals native to Africa. They have a long snout, similar to that of a pig, which is used to sniff out food.\n",
      "\n",
      "Aardvarks are the only living species of the order Tubulidentata, although other prehistoric species and genera of Tubulidentata are known. They are afrotheres, a clade that also includes elephants, manatees, and hyraxes.\n",
      "\n",
      "They are found over much of the southern two-thirds of the African continent, avoiding areas that are mainly rocky. Nocturnal feeders, aardvarks subsist on ants and termites by using their sharp claws and powerful legs to dig the insects out of their hills. Aardvarks also dig to create burrows in which to live and rear their young.\n",
      "\n",
      "Aardvarks are listed as \"least concern\" by the IUCN, although their numbers are decreasing.\n",
      "</source_1>\n",
      "\n",
      "REASONING (trunc):\n",
      " ### 1. Query decomposition\n",
      "\n",
      "User seeks comparative analysis: \"aardvarks compare to other burrowing mammals in terms of digging efficiency\" → requires quantitative/qualitative data on digging performance across species + methodological framework for efficiency measurement.\n",
      "\n",
      "Key components needed:\n",
      "- Aardvark digging capabilities (baseline data)\n",
      "- Comparative data on other burrowing mammals  \n",
      "- Efficiency metrics or performance indicators\n",
      "- Methodological context for digging efficiency studies\n",
      "\n",
      "### 2. Source examination\n",
      "\n",
      "Available source provides basic taxonomic information:\n",
      "\n",
      "\"Aardvarks are medium-sized, burrowing, nocturnal mammals native to Africa. They have a long snout, similar to that of a pig, which is used to sniff out food. They are found over much of the southern two-thirds of the African continent, avoiding areas that are mainly rocky. Nocturnal feeders, aardvarks subsist on ants \n",
      "\n",
      "ANSWER (trunc):\n",
      " Based on the provided source, it is not possible to compare the digging efficiency of aardvarks to that of other burrowing mammals. The source only offers a general description of aardvarks, noting that they are \"burrowing, nocturnal mammals\" that use \"their sharp claws and powerful legs to dig the insects out of their hills\" and to create burrows<ref name=\"source_1\">Nocturnal feeders, aardvarks subsist on ants and termites by using their sharp claws and powerful legs to dig the insects out of their hills. Aardvarks also dig to create burrows in which to live and rear their young.</ref>. It provides no data, statistics, or analysis regarding their digging efficiency relative to other animals.\n",
      "\n",
      "====================================================================================================\n",
      "exercise: math mcq | id: mcq_math_3_160900 | lang: en | model: qwen-3-8b-mcq-math+deepseek-prover-8b-solving\n",
      "\n",
      "QUERY:\n",
      " During the inaugural tests of a new particle accelerator, a system's performance was measured by a score. The initial score was 7. After a successful test, the score was increased by 2%. However, a subsequent technical issue caused the score to drop by 75%. What was the net percentage change in the system's performance score from the beginning of the tests to the end?\n",
      "\n",
      "A. -74.5%\n",
      "B. 74.5%\n",
      "C. -73.0%\n",
      "D. -75.0%\n",
      "\n",
      "SEED (trunc):\n",
      " Inaugural tests (2008)\n",
      "\n",
      "The first beam was circulated through the collider on the morning of 10 September 2008. CERN successfully fired the protons around the tunnel in stages, three kilometres at a time. The particles were fired in a clockwise direction into the accelerator and successfully steered around it at 10:28 local time. The LHC successfully completed its major test: after a series of trial runs, two white dots flashed on a computer screen showing the protons travelled the full length of the collider. It took less than one hour to guide the stream of particles around its inaugural circuit. CERN next successfully sent a beam of protons in an anticlockwise direction, taking slightly longer at one and a half hours owing to a problem with the cryogenics, with the full circuit being completed at 14:59.\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " result:-74.5\n",
      "\n",
      "REASONING (trunc):\n",
      "  #1 Initial setup, percentage calculations\n",
      "\n",
      "Start: Score = 7\n",
      "After +2% increase: New score = 7 × 1.02 = 7.14\n",
      "\n",
      "Wait. Let me recalculate this more carefully.\n",
      "7 + (2% of 7) = 7 + 0.14 = 7.14 ✓\n",
      "\n",
      "So score becomes 7.14 after the first change.\n",
      "\n",
      "#2 The problematic drop\n",
      "\n",
      "Score drops by 75% of the new value (7.14):\n",
      "Drop amount = 75% × 7.14 = 0.75 × 7.14 = 5.355\n",
      "\n",
      "Final score = 7.14 - 5.355 = 1.785\n",
      "\n",
      "Hmm, let me double-check this calculation:\n",
      "7.14 × 0.75 = 5.355 ✓\n",
      "7.14 - 5.355 = 1.785 ✓\n",
      "\n",
      "#3 Computing the net change\n",
      "\n",
      "Initial: 7\n",
      "Final: 1.785\n",
      "\n",
      "Net change = 1.785 - 7 = -5.215\n",
      "\n",
      "Percentage change = (-5.215)/7 = -0.745 = -74.5%\n",
      "\n",
      "! Key insight: The system ends up performing much worse than it started, despite the +2% improvement followed by a catastrophic 75% drop.\n",
      "\n",
      "#4 Verification against choices\n",
      "\n",
      "Looking at the options:\n",
      "A. -74.5% ← matches our calculation\n",
      "B. 74.5% ← wrong sign\n",
      "C. -73.0% ← too small magnitu\n",
      "\n",
      "ANSWER (trunc):\n",
      " A. 74.5%\n",
      "\n",
      "====================================================================================================\n",
      "exercise: editing | id: synth_dataset_editing_3_110666 | lang: en | model: qwen-3-8b-editing\n",
      "\n",
      "QUERY:\n",
      " Hi, um, I have this text about Native American stuff but I think there's some mistakes in it and it's kinda hard to read. Can you fix the errors and make it easier to understand? Also maybe add some more details so it's more interesting?\n",
      "\n",
      "Here's what I have:\n",
      "\n",
      "Religion\n",
      "\n",
      "The Pueblo religion includes more than 500 divine and ancestral spirits. These spirits are believed to interact with humans during rituals, where performers, adorned in Kachina masks and attire, are thought to transform into the spirits they represent.\n",
      "\n",
      "I think \"Kachina\" might be spelled wrong and maybe change \"divine and ancestral spirits\" to something simpler? And it needs more info about what these rituals actually look like and stuff. Oh and can you make it sound less like a textbook?\n",
      "\n",
      "SEED (trunc):\n",
      " The Pueblo religion includes more than 500 divine and ancestral spirits. These spirits are believed to interact with humans during rituals, where performers, adorned in Kachina masks and attire, are thought to transform into the spirits they represent.\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " quality:corruption, stylistic:tone, structural:expansion\n",
      "\n",
      "REASONING (trunc):\n",
      " \n",
      "\n",
      "ANSWER (trunc):\n",
      " The spiritual traditions of the Pueblo peoples are rich and diverse, encompassing a vast array of spiritual forces. Their belief system recognizes a wide variety of deities and ancestral spirits, though the most prominent are the Katsinam. These are a class of powerful spiritual beings—including figures like the Corn Maiden, the Thunder Boy, and the Cloud Serpent—who govern the natural and spiritual worlds.\n",
      "\n",
      "During sacred ceremonies and dances, performers undergo a remarkable transformation to embody these Katsinam. Adorned in intricately carved wooden masks and ceremonial attire, they become living conduits for the spirits they represent. Through the power of their songs, dances, and prayers, the performers are believed to call the Katsinam down from the higher realms to interact directly with the people. This process is a core part of the Pueblo way of life, serving to ensure blessings\n",
      "\n",
      "====================================================================================================\n",
      "exercise: creative writing | id: creative_writing_7_20780 | lang: en | model: qwen-3-8b-creative-writing\n",
      "\n",
      "QUERY:\n",
      " Please create a political thriller that employs the palimpsestic nature of Prague's administrative history as its structural foundation. The narrative should unfold over the span of a municipal election cycle, allowing for the gradual revelation of how decades-old cadastral divisions and territorial fragmentations continue to shape contemporary power dynamics. I'd like the protagonist to be a veteran city planner or urban historian—someone intimately familiar with the 1949 administrative restructuring and its lasting consequences—who discovers evidence of institutional corruption embedded within the city's bureaucratic architecture. The setting should be rigorously anchored in Prague's current municipal districts, with each chapter exploring different administrative territories to mirror the fragmented nature of the city's governance. I'm particularly interested in how the narrative migh\n",
      "\n",
      "SEED (trunc):\n",
      " Administrative division\n",
      "\n",
      "Prague is the capital of the Czech Republic and as such is the regular seat of its central authorities. Since 24 November 1990, it is de facto again a statutory city, but has a specific status of the municipality and the region at the same time. Prague also houses the administrative institutions of the Central Bohemian Region.\n",
      "\n",
      "Until 1949, all administrative districts of Prague were formed by the whole one or more cadastral unit, municipality or town. Since 1949, there has been a fundamental change in the administrative division. Since then, the boundaries of many urban districts, administrative districts and city districts are independent of the boundaries of cadastral territories and some cadastral territories are thus divided into administrative and self-governing parts of the city. Cadastral area (for example, Vinohrady and Smíchov) are still relevant especia\n",
      "\n",
      "CONSTRAINTS (trunc):\n",
      " form:Narrative, temporal:diegetic_time, stylistic:genre, character:protagonist, spatial:place\n",
      "\n",
      "REASONING (trunc):\n",
      " **Query analysis:**\n",
      "\n",
      "\"palimpsestic nature of Prague's administrative history as structural foundation\"\n",
      "\n",
      "→ Palimpsest = manuscript reused, earlier text showing through. Prague's territorial layers.\n",
      "\n",
      "\"cadastral divisions and territorial fragmentations\"\n",
      "\n",
      "→ Specific: 1949 administrative restructuring. Communist-era boundaries.\n",
      "\n",
      "\"institutional corruption embedded within bureaucratic architecture\"\n",
      "\n",
      "→ Not street-level crime. Systematic. Architectural.\n",
      "\n",
      "\"veteran city planner or urban historian\"\n",
      "\n",
      "→ Protagonist profile. Knowledgeable. Obsessive.\n",
      "\n",
      "\"each chapter exploring different administrative territories\"\n",
      "\n",
      "→ Geographic structure. Districts as narrative containers.\n",
      "\n",
      "\"tension between cadastral integrity and political expediency\"\n",
      "\n",
      "→ Core conflict. Maps vs. power. History vs. opportunism.\n",
      "\n",
      "**Complexity assessment:** ●\n",
      "\n",
      "Not simple text creation. Requires:\n",
      "- Historical research (Prague 1949)\n",
      "- Urban p\n",
      "\n",
      "ANSWER (trunc):\n",
      " **I. Městská Část 1 – Malá Strana a Hrad (Prague 1)**\n",
      "\n",
      "The first tremor came not as a sound but as a ghost on paper. Bedřich Vodička, a man whose life had been a quiet cartography of the city’s accreted layers, found it in a folio of cadastral surveys from 1928, tucked into a drawer marked with the faded label of the First Republic’s Ministry of the Interior. He was working in the sub-basement archives of the Municipal Planning Institute, a place where the air itself seemed stratified with the dust of forgotten ordinances and the spectral presence of long-vanished planners. His official task was a dry historical review for the upcoming municipal elections, but his true obsession was the city’s hidden architecture of power.\n",
      "\n",
      "He was tracing the serpentine boundaries of the Old Town’s cadastral territory when he saw it: a small, perfectly delineated parcel on the western edge of Malá Strana\n"
     ]
    }
   ],
   "source": [
    "top_ex = df[\"exercise\"].value_counts().head(8).index.tolist()\n",
    "\n",
    "for ex in top_ex:\n",
    "    row = df[df[\"exercise\"] == ex].sample(1, random_state=0).iloc[0]\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"exercise:\", ex, \"| id:\", row[\"synth_id\"], \"| lang:\", row[\"language\"], \"| model:\", row[\"model\"])\n",
    "    print(\"\\nQUERY:\\n\", (row[\"query\"] or \"\")[:900])\n",
    "    seed = row[\"query_seed_text\"] or \"\"\n",
    "    if seed:\n",
    "        print(\"\\nSEED (trunc):\\n\", seed[:900])\n",
    "    cons = row[\"constraints\"] or \"\"\n",
    "    if cons:\n",
    "        print(\"\\nCONSTRAINTS (trunc):\\n\", cons[:900])\n",
    "    print(\"\\nREASONING (trunc):\\n\", (row[\"synthetic_reasoning\"] or \"\")[:900])\n",
    "    print(\"\\nANSWER (trunc):\\n\", (row[\"synthetic_answer\"] or \"\")[:900])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0d89a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>empty_reasoning_frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constrained writing</th>\n",
       "      <td>316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>editing</th>\n",
       "      <td>159</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math mcq</th>\n",
       "      <td>177</td>\n",
       "      <td>0.096045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative writing</th>\n",
       "      <td>148</td>\n",
       "      <td>0.067568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memorization</th>\n",
       "      <td>18152</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooking</th>\n",
       "      <td>95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math exercise</th>\n",
       "      <td>333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcq</th>\n",
       "      <td>414</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rag</th>\n",
       "      <td>206</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  empty_reasoning_frac\n",
       "exercise                                        \n",
       "constrained writing    316              1.000000\n",
       "editing                159              1.000000\n",
       "math mcq               177              0.096045\n",
       "creative writing       148              0.067568\n",
       "memorization         18152              0.000110\n",
       "cooking                 95              0.000000\n",
       "math exercise          333              0.000000\n",
       "mcq                    414              0.000000\n",
       "rag                    206              0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87310/1889076166.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  \"mismatch_count\": int(df_tmp[\"result_mismatch\"].fillna(False).sum()),\n",
      "/tmp/ipykernel_87310/1889076166.py:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  (df_tmp.loc[df_tmp[\"has_expected\"], \"result_mismatch\"].fillna(False).mean())\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# assumes your sampled dataframe is named `df` and has columns:\n",
    "# [\"exercise\",\"synthetic_reasoning\",\"synthetic_answer\",\"constraints\"]\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip()).lower()\n",
    "\n",
    "# 1) Empty reasoning fraction by exercise\n",
    "reasoning_empty = df[\"synthetic_reasoning\"].fillna(\"\").astype(str).str.strip().eq(\"\")\n",
    "empty_reasoning_by_ex = (\n",
    "    df.assign(reasoning_empty=reasoning_empty)\n",
    "    .groupby(\"exercise\")[\"reasoning_empty\"]\n",
    "    .agg([\"count\", \"mean\"])\n",
    "    .rename(columns={\"mean\": \"empty_reasoning_frac\"})\n",
    "    .sort_values(\"empty_reasoning_frac\", ascending=False)\n",
    ")\n",
    "display(empty_reasoning_by_ex)\n",
    "\n",
    "# 2) constraints \"result:\" mismatch rate (very rough)\n",
    "# We look for patterns like \"result:15\" or \"result:-74.5\" (case-insensitive).\n",
    "_result_re = re.compile(r\"(?i)\\bresult\\s*:\\s*([^\\n\\r,;]+)\")\n",
    "\n",
    "def extract_expected_result(constraints: str):\n",
    "    m = _result_re.search(constraints or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    return m.group(1).strip()\n",
    "\n",
    "def result_mismatch(expected: str | None, answer: str) -> bool | None:\n",
    "    if expected is None:\n",
    "        return None\n",
    "    exp = _norm(expected)\n",
    "    ans = _norm(answer)\n",
    "\n",
    "    # if expected is a single letter (mcq), try to match \"A\" etc.\n",
    "    if re.fullmatch(r\"[a-d]\", exp):\n",
    "        # consider \"A.\" / \"A)\" / \"A\" / \"Answer: A\" as match\n",
    "        return (re.search(rf\"\\b{re.escape(exp)}\\b\", ans) is None)\n",
    "\n",
    "    # numeric-ish: just require the expected substring appears somewhere\n",
    "    # (handles \"15\", \"-74.5%\", etc. but is not a full verifier)\n",
    "    return (exp not in ans)\n",
    "\n",
    "expected = df[\"constraints\"].astype(str).map(extract_expected_result)\n",
    "has_expected = expected.notna()\n",
    "\n",
    "mismatch = []\n",
    "for exp, ans in zip(expected.tolist(), df[\"synthetic_answer\"].fillna(\"\").astype(str).tolist()):\n",
    "    mm = result_mismatch(exp, ans)\n",
    "    mismatch.append(mm)\n",
    "\n",
    "df_tmp = df.assign(expected_result=expected, has_expected=has_expected, result_mismatch=mismatch)\n",
    "\n",
    "summary = {\n",
    "    \"rows_total\": len(df_tmp),\n",
    "    \"rows_with_result_constraint\": int(df_tmp[\"has_expected\"].sum()),\n",
    "    \"result_constraint_frac\": float(df_tmp[\"has_expected\"].mean()),\n",
    "    \"mismatch_count\": int(df_tmp[\"result_mismatch\"].fillna(False).sum()),\n",
    "    \"mismatch_frac_given_result\": float(\n",
    "        (df_tmp.loc[df_tmp[\"has_expected\"], \"result_mismatch\"].fillna(False).mean())\n",
    "        if df_tmp[\"has_expected\"].any()\n",
    "        else 0.0\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db791efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87310/1202567828.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_tmp[df_tmp[\"has_expected\"] & df_tmp[\"result_mismatch\"].fillna(False)][\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise</th>\n",
       "      <th>synth_id</th>\n",
       "      <th>expected_result</th>\n",
       "      <th>synthetic_answer</th>\n",
       "      <th>constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_29_2664</td>\n",
       "      <td>16020</td>\n",
       "      <td>**16,020 pounds**\\n\\nThis is a multi-step word...</td>\n",
       "      <td>result:16020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_59_14090</td>\n",
       "      <td>-2709</td>\n",
       "      <td>**Answer: -2,709 units remain to be analyzed**...</td>\n",
       "      <td>result:-2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_61_3746</td>\n",
       "      <td>-195.45</td>\n",
       "      <td>**Answer: -$195.45**\\n\\nThis is an optimizatio...</td>\n",
       "      <td>result:-195.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_66_13865</td>\n",
       "      <td>20520</td>\n",
       "      <td>**Answer: 20,520 units**\\n\\nThis problem invol...</td>\n",
       "      <td>result:20520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_57_11322</td>\n",
       "      <td>114240</td>\n",
       "      <td>**114,240 cycles**\\n\\nThis is a **scaling prob...</td>\n",
       "      <td>result:114240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>math mcq</td>\n",
       "      <td>mcq_math_3_236012</td>\n",
       "      <td>672882</td>\n",
       "      <td>A. 672,882</td>\n",
       "      <td>result:672882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_80_14169</td>\n",
       "      <td>-20</td>\n",
       "      <td>**The studio's net financial outcome for the c...</td>\n",
       "      <td>result:-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_80_1475</td>\n",
       "      <td>2941</td>\n",
       "      <td>**The total cost for the entire order is 2,941...</td>\n",
       "      <td>result:2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>math exercise</td>\n",
       "      <td>synth_math_87_14426</td>\n",
       "      <td>1166083.1</td>\n",
       "      <td>**The final converted area is 1,166,083.1 hect...</td>\n",
       "      <td>result:1166083.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>math mcq</td>\n",
       "      <td>mcq_math_2_133349</td>\n",
       "      <td>Failed after maximum attempts</td>\n",
       "      <td>A. `dL/dt = r × F`</td>\n",
       "      <td>result:Failed after maximum attempts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           exercise             synth_id                expected_result  \\\n",
       "118   math exercise   synth_math_29_2664                          16020   \n",
       "348   math exercise  synth_math_59_14090                          -2709   \n",
       "380   math exercise   synth_math_61_3746                        -195.45   \n",
       "989   math exercise  synth_math_66_13865                          20520   \n",
       "1163  math exercise  synth_math_57_11322                         114240   \n",
       "1451       math mcq    mcq_math_3_236012                         672882   \n",
       "1671  math exercise  synth_math_80_14169                            -20   \n",
       "1737  math exercise   synth_math_80_1475                           2941   \n",
       "1927  math exercise  synth_math_87_14426                      1166083.1   \n",
       "2059       math mcq    mcq_math_2_133349  Failed after maximum attempts   \n",
       "\n",
       "                                       synthetic_answer  \\\n",
       "118   **16,020 pounds**\\n\\nThis is a multi-step word...   \n",
       "348   **Answer: -2,709 units remain to be analyzed**...   \n",
       "380   **Answer: -$195.45**\\n\\nThis is an optimizatio...   \n",
       "989   **Answer: 20,520 units**\\n\\nThis problem invol...   \n",
       "1163  **114,240 cycles**\\n\\nThis is a **scaling prob...   \n",
       "1451                                         A. 672,882   \n",
       "1671  **The studio's net financial outcome for the c...   \n",
       "1737  **The total cost for the entire order is 2,941...   \n",
       "1927  **The final converted area is 1,166,083.1 hect...   \n",
       "2059                                 A. `dL/dt = r × F`   \n",
       "\n",
       "                               constraints  \n",
       "118                           result:16020  \n",
       "348                           result:-2709  \n",
       "380                         result:-195.45  \n",
       "989                           result:20520  \n",
       "1163                         result:114240  \n",
       "1451                         result:672882  \n",
       "1671                            result:-20  \n",
       "1737                           result:2941  \n",
       "1927                      result:1166083.1  \n",
       "2059  result:Failed after maximum attempts  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_tmp[df_tmp[\"has_expected\"] & df_tmp[\"result_mismatch\"].fillna(False)][\n",
    "    [\"exercise\",\"synth_id\",\"expected_result\",\"synthetic_answer\",\"constraints\"]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397aeaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87310/2003069061.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  \"mismatch_frac_given_result\": float(df_check.loc[has_expected, \"result_mismatch\"].fillna(False).mean()) if has_expected.any()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "_result_re = re.compile(r\"(?i)\\bresult\\s*:\\s*([^\\n\\r,;]+)\")\n",
    "_num_re = re.compile(r\"[-+]?\\d[\\d,]*(?:\\.\\d+)?\")\n",
    "\n",
    "def extract_expected_result(constraints: str):\n",
    "    m = _result_re.search(constraints or \"\")\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def first_answer_line(ans: str) -> str:\n",
    "    for line in (ans or \"\").splitlines():\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            return line\n",
    "    return \"\"\n",
    "\n",
    "def parse_first_number(s: str):\n",
    "    m = _num_re.search(s or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    return float(m.group(0).replace(\",\", \"\"))\n",
    "\n",
    "def expected_is_failed(expected: str) -> bool:\n",
    "    return (expected or \"\").strip().lower().startswith(\"failed after maximum attempts\")\n",
    "\n",
    "def result_mismatch(expected: str | None, answer: str, atol=1e-6, rtol=1e-6) -> bool | None:\n",
    "    if expected is None:\n",
    "        return None\n",
    "    if expected_is_failed(expected):\n",
    "        return True  # treat as unusable / drop\n",
    "\n",
    "    exp_num = parse_first_number(expected)\n",
    "    ans_line = first_answer_line(answer)\n",
    "    ans_num = parse_first_number(ans_line)\n",
    "\n",
    "    # if we can compare as numbers, do so\n",
    "    if exp_num is not None and ans_num is not None:\n",
    "        return not math.isclose(exp_num, ans_num, rel_tol=rtol, abs_tol=atol)\n",
    "\n",
    "    # fallback: normalized substring match on first line\n",
    "    exp_norm = re.sub(r\"\\s+\", \" \", expected.strip()).lower()\n",
    "    ans_norm = re.sub(r\"\\s+\", \" \", ans_line.strip()).lower()\n",
    "    return exp_norm not in ans_norm\n",
    "\n",
    "expected = df[\"constraints\"].astype(str).map(extract_expected_result)\n",
    "mismatch = [\n",
    "    result_mismatch(exp, ans)\n",
    "    for exp, ans in zip(expected.tolist(), df[\"synthetic_answer\"].fillna(\"\").astype(str).tolist())\n",
    "]\n",
    "\n",
    "df_check = df.assign(expected_result=expected, result_mismatch=mismatch)\n",
    "has_expected = df_check[\"expected_result\"].notna()\n",
    "\n",
    "summary = {\n",
    "    \"rows_total\": len(df_check),\n",
    "    \"rows_with_result_constraint\": int(has_expected.sum()),\n",
    "    \"result_constraint_frac\": float(has_expected.mean()),\n",
    "    \"mismatch_frac_given_result\": float(df_check.loc[has_expected, \"result_mismatch\"].fillna(False).mean()) if has_expected.any()\n",
    "else 0.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45356ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows_total': 20000,\n",
       " 'rows_with_result_constraint': 511,\n",
       " 'result_constraint_frac': 0.02555,\n",
       " 'mismatch_frac_given_result': 0.12524461839530332}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
